{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install trash-cli\n",
    "trash-empty\n",
    "cd /mnt/tempvol/home/ubuntu/Desktop/Ctdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.Session(config=config)\n",
    "import pydicom\n",
    "import re\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    count = 0\n",
    "    for i in range(0, len(l), n):\n",
    "        if (count < NoSlices):\n",
    "            yield l[i:i + n]\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)\n",
    "def normalize2(image):\n",
    "    mean = image.mean()\n",
    "    if mean >0:\n",
    "        MIN_BOUND = 0\n",
    "        MAX_BOUND = 1024\n",
    "    else:\n",
    "        MIN_BOUND = -1024\n",
    "        MAX_BOUND = 0\n",
    "        \n",
    "    image[image == -2000] = 0\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    \n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image\n",
    "def get_segmented_lungs(im, plot=False):\n",
    "\n",
    "    binary = im < -400\n",
    "\n",
    "    cleared = clear_border(binary)\n",
    "\n",
    "    label_image = label(cleared)\n",
    "\n",
    "    areas = [r.area for r in regionprops(label_image)]\n",
    "    areas.sort()\n",
    "    if len(areas) > 2:\n",
    "        for region in regionprops(label_image):\n",
    "            if region.area < areas[-2]:\n",
    "                for coordinates in region.coords:                \n",
    "                       label_image[coordinates[0], coordinates[1]] = 0\n",
    "    binary = label_image > 0\n",
    "\n",
    "    edges = roberts(binary)\n",
    "    binary = ndi.binary_fill_holes(edges)\n",
    "\n",
    "    get_high_vals = binary == 0\n",
    "    im[get_high_vals] = 0\n",
    "\n",
    "        \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eben0=os.listdir(r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/0/\")\n",
    "eben1=os.listdir(r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/1/\")\n",
    "eben2=os.listdir(r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/2/\")\n",
    "eben3=os.listdir(r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct0=[]\n",
    "ct1=[]\n",
    "ct2=[]\n",
    "ct3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlabeledProcessing(patient, size,noslices):\n",
    "        path = dataDirectory + patient + \"/stu01\" + \"/ser01\"\n",
    "        if 'stu02' in os.listdir(dataDirectory + patient):\n",
    "            path=dataDirectory + patient + \"/stu02\" + \"/ser01\"\n",
    "        data4 = os.listdir(path)\n",
    "        data4.sort()\n",
    "        data5 = data4\n",
    "        minv=round(len(data5)/4)\n",
    "        maxv=round(len(data5)/1.7)\n",
    "        if len(data5)<113:\n",
    "            maxv=round(len(data5)/1.29)\n",
    "        if len(data5)<50:\n",
    "            minv=0\n",
    "            maxv=round(len(data5)/1)\n",
    "        data5=data5[minv:maxv]\n",
    "        slices = [pydicom.read_file(path + '/' + s) for s in data5]\n",
    "        #slices.sort(key=lambda x: int(x.ImagePositionPatient[2]))\n",
    "        slices = get_pixels_hu(slices)\n",
    "\n",
    "        new_slices = []\n",
    "        slices = [normalize2(get_segmented_lungs(cv2.resize(np.array(each_slice), (size, size)))) for each_slice in slices]\n",
    "\n",
    "        chunk_sizes = math.floor(len(slices) / noslices)\n",
    "        for slice_chunk in chunks(slices, chunk_sizes):\n",
    "            slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "            new_slices.append(slice_chunk)\n",
    "        if not new_slices:\n",
    "            print(\"Could not create test set\")\n",
    "        else:\n",
    "            var.append(np.array(new_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoSlices=25\n",
    "#dataDirectory = r\"/home/ubuntu/ctdata/3/\"\n",
    "#lungPatients = os.listdir(dataDirectory)\n",
    "for i in range(4):\n",
    "    if i ==0:\n",
    "        var = ct0\n",
    "        dataDirectory=r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/0/\"\n",
    "        lungPatients = eben0\n",
    "    if i ==1:\n",
    "        var = ct1\n",
    "        dataDirectory=r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/1/\"\n",
    "        lungPatients = eben1\n",
    "    if i ==2:\n",
    "        var = ct2\n",
    "        dataDirectory=r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/2/\"\n",
    "        lungPatients = eben2\n",
    "    if i ==3:\n",
    "        var = ct3\n",
    "        dataDirectory=r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/3/\"\n",
    "        lungPatients = eben3\n",
    "    print(i)\n",
    "    for  patient in lungPatients:\n",
    "        unlabeledProcessing(patient, size=144, noslices=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDirectory=r\"/mnt/tempvol/home/ubuntu/ctdata/0/\"\n",
    "lungPatients = eben0\n",
    "for  patient in lungPatients:\n",
    "        unlabeledProcessing(patient, size=180, noslices=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct0 = np.array(ct0)\n",
    "ct1 = np.array(ct1)\n",
    "ct2 = np.array(ct2)\n",
    "ct3 = np.array(ct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct0[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ct1[4][18],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('CTSEG192-40.npy',data)\n",
    "np.save('ct0.npy',ct0)\n",
    "np.save('ct1.npy',ct1)\n",
    "np.save('ct2.npy',ct2)\n",
    "np.save('ct3.npy',ct3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct0 = np.load(\"ct0.npy\",allow_pickle=True)\n",
    "ct1 = np.load(\"ct1.npy\",allow_pickle=True)\n",
    "ct2 = np.load(\"ct2.npy\",allow_pickle=True)\n",
    "ct3 = np.load(\"ct3.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/ubuntu/Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"CTSEG192-40.npy\",allow_pickle=True)\n",
    "#data = np.load(\"CTSEG180-25.npy\",allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.load(\"test.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ml=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ct0.shape[0]):\n",
    "    y_ml.append(0)\n",
    "\n",
    "for i in range(ct1.shape[0]):\n",
    "    y_ml.append(1)\n",
    "\n",
    "for i in range(ct2.shape[0]):\n",
    "    y_ml.append(1)\n",
    "\n",
    "for i in range(ct3.shape[0]):\n",
    "    y_ml.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_ml= to_categorical(y_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct0=data[:122]#122\n",
    "ct1=data[122:211]\n",
    "ct2=data[211:277]\n",
    "ct3=data[277:295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,\n",
    "    ToFloat, ShiftScaleRotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "zenci = Compose([ShiftScaleRotate(rotate_limit=17,scale_limit=0.07,p=0.85,shift_limit=0.0500),\n",
    "    HorizontalFlip(p=0.85)],additional_targets={'image00': 'image', 'image01': 'image',\"image02\":\"image\",\"image03\":\"image\",\"image04\":\"image\",\"image05\":\"image\",\"image06\":\"image\",\"image07\":\"image\",\"image08\":\"image\",\"image9\":\"image\",\"image10\":\"image\",\"image11\":\"image\",\"image12\":\"image\",\"image13\":\"image\",\"image14\":\"image\",\"image15\":\"image\",\"image16\":\"image\",\"image17\":\"image\",\"image18\":\"image\",\"image19\":\"image\",\"image20\":\"image\",\"image21\":\"image\",\"image22\":\"image\",\"image23\":\"image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ct3[1][20],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(z1[1][20],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1=[]\n",
    "for j in range(len(ct1)):\n",
    "    for i in range(25):\n",
    "            if i==0:\n",
    "                globals()[\"image\"] = ct3[j][i]\n",
    "            if i>9:\n",
    "                globals()[\"image\" + str(i-1)] = ct3[j][i]\n",
    "            else:\n",
    "                globals()[\"image0\" + str(i-1)] = ct3[j][i]\n",
    "                \n",
    "    transformed = zenci(image=image, image00=image00, image01=image01,image02=image02,image03=image03,image04=image04,image05=image05,image06=image06,image07=image07,image08=image08,image9=image9,image10=image10,image11=image11,image12=image12,image13=image13,image14=image14,image15=image15,image16=image16,image17=image17,image18=image18,image19=image19,image20=image20,image21=image21,image22=image22,image23=image23)\n",
    "    z1.append(list(transformed.values()))\n",
    "z1 = np.array(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = np.concatenate([ct1,z1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ct0[127][19],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ct2[110][10],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct11= np.concatenate([ct1,ct2,ct3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct11= np.concatenate([ct1[:100],ct2[:110],ct3[:40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([ct0,ct11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.concatenate([ct0,ct1,ct2,ct3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 40, 144, 144)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_ml, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.reshape(X_train.shape[0], 25,144,144,1) #reshaping\n",
    "X_test = X_test.reshape(X_test.shape[0], 25,144,144,1) # reshaping also for adding color dimension 1 for grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.reshape(X_train.shape[0], 40,144,144,1) \n",
    "X_test = X_test.reshape(X_test.shape[0], 40,144,144,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization,Activation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), input_shape=(40,144,144,1),activation=\"relu\"))\n",
    "model.add(MaxPool3D(pool_size=(2, 2, 2),strides=(2,2,2),padding='same'))\n",
    "model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv3D(filters=128, kernel_size=(3, 3, 3), activation='relu'))\n",
    "model.add(MaxPool3D(pool_size=(2, 2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/1\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "324/324 [==============================] - 64s 199ms/step - loss: 0.8893 - acc: 0.5216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce62351860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=.00001), metrics=['acc'])\n",
    "model.fit(X_train,y_train, batch_size=4,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('covidctMLBig_model.h5',include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('covidctMLBig_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=.0001), metrics=['acc'])\n",
    "model.fit(X_train,y_train, batch_size=8,epochs=145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAELCAYAAAAiIMZEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcJElEQVR4nO3debQdVZn38e8vAwKBMBOSEIkIgoAYuiGI2G+DaBhEQgsdgm9LwOAFlRZebRRBgQYU2mYQOyJEiQEXBhCZloQhJmLEJpgQQQnzKJkJwRAISu69z/tHVcLh5NQ9de89OUPl92HVOqd27ap6QrKeu++uXXsrIjAzs2Lp0+gAzMys9pzczcwKyMndzKyAnNzNzArIyd3MrID6NTqA7li97HkP7bF17L77sY0OwZrQc8vmqrfX6E7O6b/tzr2+Xy255W5mVkAt1XI3M6urzo5GR9BjTu5mZlk62hsdQY85uZuZZYjobHQIPebkbmaWpdPJ3cyseNxyNzMrID9QNTMrILfczcyKJzxaxsysgPxA1cysgNwtY2ZWQH6gamZWQG65m5kVkB+ompkVkB+ompkVT0Tr9rl7PnczsyzRmX/rgqRhkn4j6XFJ8ySdnpZvLWmapGfSz60yzh+X1nlG0rg8oTu5m5ll6ezMv3WtHfhaROwBfAT4sqQ9gLOA6RGxKzA93X8XSVsD5wH7AyOB87J+CJRycjczy1KjlntELIqIuen3lcATwFBgNHBdWu064OgKpx8KTIuI5RHxGjANOKxa6O5zNzPL0rE6d1VJbUBbSdHEiJhYod5wYB/gIWBQRCxKDy0GBlW49FDg5ZL9+WlZl5zczcyydGO0TJrI10nmpSRtBvwSOCMiXpfeWVM7IkJS7gW5q3G3jJlZlhp1ywBI6k+S2G+IiFvT4iWSBqfHBwNLK5y6ABhWsr9jWtYlJ3czsyw1eqCqpIl+LfBERFxecuhOYM3ol3HAHRVOvxcYJWmr9EHqqLSsS+6WMTPLUruXmA4EPgf8WdIjadnZwCXAzZLGAy8BYwAk7QucGhEnR8RySRcCs9PzLoiI5dVu6ORuZpYhuvFAtcvrRDwAKOPwIRXqzwFOLtmfBEzqzj2d3M3MsnjiMDOzAvLcMmZmBeSWu5lZAbnlbmZWQG65m5kVULsX6zAzKx633M3MCsh97mZmBeSWu5lZAbnlbmZWQG65m5kVkEfLmJkVUNRs7Yy6c3I3M8viPnczswJycjczKyA/UDUzK6COjppdStIk4EhgaUTslZbdBOyWVtkS+GtEjKhw7ovASqADaI+Ifavdz8ndzCxLbbtlJgMTgOvXFETEcWu+S7oMWNHF+QdHxLK8N3NyNzPLUsPkHhEzJQ2vdCxdQHsM8PFa3a9PrS5kZlY40Zl7k9QmaU7J1taNO/0TsCQinsmKBLhP0sN5r+uWu5lZhujMP849IiYCE3t4q+OBKV0c/1hELJC0PTBN0pMRMbOrCzq5m5llqcNQSEn9gM8A/5hVJyIWpJ9LJd0GjAS6TO7uljEzy9LRkX/ruU8AT0bE/EoHJQ2QtPma78Ao4LFqF3VyNzPL0tmZf6tC0hTgQWA3SfMljU8PjaWsS0bSEElT091BwAOSHgX+ANwVEfdUu5+7ZczMstR2tMzxGeUnVihbCByRfn8e+HB37+fk3gIWLXmFsy+8lFdfew0hjh19OJ8bczSXTvgJv/39Q/Tr349hQwdz0dlfZeDmmzU6XGuAwUMGcelVF7DNdtsQEdx0/a1MntjV8znLxROH2frUr29fzvz3L7DHbrvw5purGDP+K3x0v304YL99OOPUk+jXry+XX3UtP/nZTXz1S+OrX9AKp72jg++eewXz/vQkAzbblDum38AD98/i2adfaHRorc1zy+QjaXdgNDA0LVoA3BkRT9Qzjlaz3bZbs922WwMwYMCm7LzTMJa88ioH7v/Ow/W999ydab95oFEhWoO9smQZryxJXl58841VPPv0CwwavL2Te291Yyhks6nbA1VJ3wBuBETyUOAP6fcpks6qVxytbsGiJTzxzHPsvedu7yq/7a77+NgB+zUoKmsmQ4cNZs8P7cajD1cdUGHV1Ge0zHpRz5b7eGDPiFhdWijpcmAecEmlk9K3sdoArrrsIk4+oeIziQ3CqlVv8f/OuYhvfOUUNhswYG35NddNoW/fvhw56uAGRmfNYNMBm3DV5Eu58JzLeOONNxsdTssLd8vk0gkMAV4qKx+cHquo9K2v1cueb93fkXppdXs7Z5xzEZ8adTCfPOjAteW33zWNmb//Az/5wcUk01PYhqpfv3788KeXcsctU7nvrhmNDqcYWrhbpp7J/QxguqRngJfTsvcCuwCn1TGOlhMRnHvx99l5p2GMG/uZteUPzJrDpJ//gskTvscmG2/cwAitGVxy5bk89/QLTPrRDY0OpThaeD53RR2H+kjqQ/LabOkD1dkRkavDakNtuc999DFO+NKZ7Pr+4fRR8pjk9FPGcfH3r+bt1avZcuBAIHmoet7X/72RoTbE7rsf2+gQGu4f9x/BzXdN4sl5z9CZdiVc9p0J3P/r3zc4ssZ5btncXv8q++YF/zd3zhlw7g1N9atzXZN7b22oyd265uRuldQkuZ87Nn9yv+DGpkruHuduZpalhbtlnNzNzLL4gaqZWfF4KKSZWRG55W5mVkBO7mZmBdSE0wrk5cU6zMwyRGfk3qqRNEnSUkmPlZSdL2mBpEfS7YiMcw+T9JSkZ/POxeXkbmaWpTPyb9VNBg6rUH5FRIxIt6nlByX1BX4IHA7sARwvaY9qN3NyNzPLUsNl9iJiJrC8B1GMBJ6NiOcj4m2S2XVHVzvJyd3MLEttW+5ZTpP0p7TbZqsKx4fyznxcAPN5ZwqXTE7uZmZZupHcJbVJmlOyteW4w4+A9wMjgEXAZbUK3aNlzMwyREf+l5hKpyfvxjlL1nyX9GPgVxWqLQCGlezvmJZ1yS13M7Ms67lbRtLgkt1/ASotnzUb2FXS+yRtBIwF7qx2bbfczcwy5BnimJekKcBBwLaS5gPnAQdJGgEE8CJwSlp3CPCTiDgiItolnQbcC/QFJkXEvGr3c3I3M8tSw+QeEZXWCL02o+5C4IiS/anAOsMku+LkbmaWpXXnDXNyNzPLEu2tm92d3M3MsrRubndyNzPLUssHqvXm5G5mlsUtdzOz4nHL3cysiNxyNzMrnmhvdAQ95+RuZpYh3HI3MysgJ3czs+Jxy93MrICc3M3MCig61OgQeszJ3cwsQyFb7pJu7sZ1IiKOq0E8ZmZNIzqL2XLfrm5RmJk1oUK23CPi4HoGYmbWbCJq13KXNAk4ElgaEXulZf8NfBp4G3gOOCki/lrh3BeBlUAH0B4R+1a7n9dQNTPLEJ35txwmA4eVlU0D9oqIvYGngW92cf7BETEiT2KHbjxQlbQ5MBr4ALBx+fGI+Hrea5mZtYLOGo6WiYiZkoaXld1XsjsLOLZW98uV3CW9H/hfYBNgAPAKsHV6/mvACsDJ3cwKpTsPVCW1AW0lRRMjYmI3bvd54KasUID7JAVwTZ7r5m25XwHMBv4VeJNk4dZHgeOAi9NPM7NC6U5yTxNud5L5WpLOAdqBGzKqfCwiFkjaHpgm6cmImNnVNfMm95HAycDf0/2NIqID+LmkbYErgY/mvJaZWUuIOkznLulEkgeth0RUvmNELEg/l0q6jSQnd5nc8z5Q3Rh4PSI6geXAkJJjjwEfznkdM7OWEZ3KvfWEpMNIurSPiohVGXUGpM88kTQAGEWSd7uUN7k/DeyUfv8jcKqkjSX1B8YDC3Nex8ysZUQo91aNpCnAg8BukuZLGg9MADYn6Wp5RNLVad0hkqampw4CHpD0KPAH4K6IuKfa/fJ2y9wIjAB+BnwbuBd4nWRCzL7AiTmvY2bWMjpqO1rm+ArF12bUXUjybJOIeJ4e9I7kSu4RcXnJ91mS9gIOJ+mumRERVX9FMDNrNbV8ianeejRxWES8TA+fCpuZtYqizi2zlqQjqtWJiKnV6piZtZJ6jJZZX/K23H9FMoi+/MdY6R+9b00iMjNrEoVvuQPvq1C2FXAocBJ+oGpmBdTR2brTb+V9oPpSheKXgEckdQBnA0fVMjAzs0Zr5W6ZWvxY+iPw8Rpcx8ysqXSGcm/NplfL7EnaiKRLZlFNojEzayKFHwopaTbvfngKsBEwnOTtqpNqG5aZWeO1crdM3pb7PNZN7n8DfgHcHhHzahpVhk2G/FM9bmMtZumndml0CFZQzdjdklfeB6onruc4zMyaTiuPlskVuaQZknbPOPYBSTNqG5aZWeNFN7Zmk7db5iBgYMaxgcD/qUk0ZmZNpPDdMql1fjilo2U+DiyuWURmZk2ikKNlJJ0HnJvuBjBLyvyD/neN4zIza7jORgfQC1213KcCy0jmk/kBcBnwYlmdt4EnI+J36yU6M7MGinWm02odmck9ImaTLIqNpJXAryLi1XoFZmbWaO017JaRNIlkrdSlEbFXWrY1cBPJO0MvAmMi4rUK544DvpXuXhQR11W7X95xPo8A+2cEfISkvXNex8ysZQTKveUwGTisrOwsYHpE7ApMT/ffJf0BcB5JDh4JnCdpq2o3y5vcryAjuQP7pcfNzAqlsxtbNRExE1heVjwaWNMKvw44usKphwLTImJ52qqfxro/JNaRN7n/A/D7jGMPAvvkvI6ZWcvoTstdUpukOSVbW45bDIqINXNzLSZZDLvcUODlkv35aVmX8g6F7AsMyDg2gGSeGTOzQunOaJmImEgvlh+NiJBUs/eh8rbcZwNZP4XagDm1CcfMrHl0oNxbDy2RNBgg/Vxaoc4CYFjJ/o5pWZfyttzPB34t6SGSfqHFwGDgBGAE8Imc1zEzaxl1WGXvTmAccEn6eUeFOvcC3y15iDoK+Ga1C+dquacPAkaR/JbyP8AtwJVAO3AIMCvPdczMWkknyr1VI2kKyTPK3STNlzSeJKl/UtIzJI3kS9K6+0r6CUBELAcuJOlBmQ1ckJZ1Kff0AxFxP3CApE1J1k99DfgoyWIddwJb572WmVkrqOWEYBFxfMahQyrUnQOcXLI/CZjUnfv1ZCWmvYHjgX8lebK7HJjSg+uYmTW1ok4/sJakD5Ek9LHATiTTDmwEfA2YEBHt6y1CM7MG6cyeT6vpdTVx2M4kCf144IMk/ev3Ad8Gfgv8BZjrxG5mRdXR6AB6oauW+7MkXU4PAacAv1wz54GkLeoQm5lZQ9VhtMx609VomZdIZoTci2Sxjo9K6kkfvZlZS6rlaJl662pWyPdJ+gjwWZKHp58FXpN0K3A3zbmylJlZzbRykutynHtEzIqIr5DMYzAKuB04hmScO8AXJO27fkM0M2uMTuXfmk3el5g6I+LXETGeZPjjvwA3p58PSXpiPcZoZtYQtZwVst663YceEatJXpG9I32h6WiSIZJmZoXS0YQt8rx69YA0IlYBP083M7NCacYWeV4e/WJmlsHJ3cysgGq4hGrdObmbmWVwy93MrICKOv2AmdkGrRnHr+fl5G5mlqGVu2XyrqFqZrbBqdVLTJJ2k/RIyfa6pDPK6hwkaUVJnXN7E7tb7mZmGWo1t0xEPEWy3jSS+pIscH1bhaq/i4gja3FPJ3czswzrqc/9EOC5iHhpvVw95W4ZM7MMHd3YJLVJmlOytWVcdizZS5MeIOlRSXdL2rM3sbvlbmaWobMbHTMRMRGY2FUdSRsBRwHfrHB4LrBTRLwh6QiSWXh3zR/tu7nlbmaWYT3MCnk4yfKkS8oPRMTrEfFG+n0q0F/Stj2N3cndzCxDdGPL6XgyumQk7SAlK3JLGkmSn1/taezuljEzy1DLce6SBgCfJFmTek3ZqQARcTVwLPBFSe3AW8DYiOjxgB0ndzOzDO2q3UJ7EfEmsE1Z2dUl3ycAE2p1Pyd3M7MMrbyGqpO7mVmGVp5+wMndzCxDd4ZCNhsndzOzDK2b2p3czcwyuVvGzKyAOlq47e7kbmaWwS13M7MCCrfczcyKp5Vb7p5bpgUdOuog5j02kycff4Cvn/nlRodjDTLgtG+w5eTbGXjlT9c5tvFRY9j6tt+izbdoQGTF0Unk3pqNk3uL6dOnDz+48jsc+el/40MfPpjjjjuaD36wx7OCWgv7+4y7WXnBmeuU99lmO/qP2I+OpYsbEFWxrIeJw+rGyb3FjNxvH5577kVeeOEvrF69mptvvoOjPn1oo8OyBmh//E/EypXrlG/6+dNYdf3VNGfKaS3tRO6t2Ti5t5ghQ3fg5fkL1+7PX7CIIUN2aGBE1kz6jzyQzuXL6HjxuUaHUgjRjf+aTVMkd0kndXFs7dJVnZ1v1jMss9ay0XvY5Jh/460pkxodSWGsh8U66qYpkjvwn1kHImJiROwbEfv26TOgnjE1pYULFjNsxyFr93ccOpiFC923atB3h6H0GTSYgVdcyxbX3EifbbZj4GU/Rltu3ejQWlYrt9zrNhRS0p+yDgGD6hVHq5s95xF22eV9DB8+jAULFjNmzGg+d4JHzBh0/OV5/nri0Wv3t7jmRl7/j1OIlSsaGFVrq/FiHS8CK0nW026PiH3Ljgu4EjgCWAWcGBFze3q/eo5zHwQcCrxWVi7gf+sYR0vr6Ojg9DO+xdS7fk7fPn2YfN1NPP74040OyxpgwFfPpf+eI9DALdjyx79g1Y0/5e3pUxsdVqF09HwhpCwHR8SyjGOHkyyIvSuwP/Cj9LNH6pncfwVsFhGPlB+QdH8d42h5d98zg7vvmdHoMKzB3rz8gi6PrzhlbJ0iKa46j18fDVyfLq03S9KWkgZHxKKeXKxufe4RMT4iHsg49tl6xWFmlld3+txLB3+kW9s6l4P7JD1c4RjAUODlkv35aVmPePoBM7MM3elzj4iJwMQuqnwsIhZI2h6YJunJiJjZuwizNctoGTOzplPL6QciYkH6uRS4DRhZVmUBMKxkf8e0rEec3M3MMtRqKKSkAZI2X/MdGAU8VlbtTuAEJT4CrOhpfzu4W8bMLFMNR8sMAm5LRjvSD/h5RNwj6VSAiLgamEoyDPJZkqGQmS935uHkbmaWoVajZSLieeDDFcqvLvkeQM1eWnFyNzPL0IzTCuTl5G5mlqEZpxXIy8ndzCxDMy7CkZeTu5lZhqj99AN14+RuZpahwy13M7PicbeMmVkBuVvGzKyA3HI3MysgD4U0Myug9bBYR904uZuZZXC3jJlZATm5m5kVkEfLmJkVkFvuZmYF5NEyZmYF1BGtO+mvl9kzM8sQEbm3rkgaJuk3kh6XNE/S6RXqHCRphaRH0u3c3sTulruZWYYa9rm3A1+LiLnpWqoPS5oWEY+X1ftdRBxZixs6uZuZZahVn3u60PWi9PtKSU8AQ4Hy5F4z7pYxM8vQGZF7k9QmaU7J1lbpmpKGA/sAD1U4fICkRyXdLWnP3sTulruZWYbutNwjYiIwsas6kjYDfgmcERGvlx2eC+wUEW9IOgK4Hdi1exG/wy13M7MMHdGZe6tGUn+SxH5DRNxafjwiXo+IN9LvU4H+krbtaexuuZuZZeis0RuqkgRcCzwREZdn1NkBWBIRIWkkSeP71Z7e08ndzCxDDV9iOhD4HPBnSY+kZWcD7wWIiKuBY4EvSmoH3gLGRi/mP3ByNzPLUKuWe0Q8AKhKnQnAhJrcECd3M7NMnn7AzKyAOqKj0SH0mJO7mVkGT/lrZlZAnvLXzKyA3HI3MyugWo2WaQQndzOzDB4tY2ZWQK28WIeTu5lZBve5m5kVkPvczcwKyC13M7MC8jh3M7MCcsvdzKyAPFrGzKyA/EDVzKyAWrlbxmuomplliG78V42kwyQ9JelZSWdVOP4eSTelxx+SNLw3sTu5m5lliIjcW1ck9QV+CBwO7AEcL2mPsmrjgdciYhfgCuC/ehO7k7uZWYbOiNxbFSOBZyPi+Yh4G7gRGF1WZzRwXfr9FuCQdGHtHmmpPvf2txf0+A9aNJLaImJio+Ow5uJ/F7XVnZwjqQ1oKymaWPJ3MRR4ueTYfGD/skusrRMR7ZJWANsAy7obN7jl3sraqlexDZD/XTRIREyMiH1Ltob+kHVyNzNb/xYAw0r2d0zLKtaR1A/YAni1pzd0cjczW/9mA7tKep+kjYCxwJ1lde4ExqXfjwVmRC/GYrZUn7u9i/tVrRL/u2hCaR/6acC9QF9gUkTMk3QBMCci7gSuBX4m6VlgOckPgB5TKw/SNzOzytwtY2ZWQE7uZmYF5OTegqq9xmwbHkmTJC2V9FijY7Hm4OTeYnK+xmwbnsnAYY0OwpqHk3vryfMas21gImImyQgLM8DJvRVVeo15aINiMbMm5eRuZlZATu6tJ89rzGa2gXNybz15XmM2sw2ck3uLiYh2YM1rzE8AN0fEvMZGZY0maQrwILCbpPmSxjc6JmssTz9gZlZAbrmbmRWQk7uZWQE5uZuZFZCTu5lZATm5m5kVkJO79Zik8yVFybZQ0i8lvX893e/I9D7D0/3h6f6R3bjGGEkn1jCmzdIYanZNs1rwMnvWWyt4ZzbCnYELgemS9oyIN9fzvRcBBwBPduOcMcC2JLMomhWWk7v1VntEzEq/z5L0F+B3wBHAL0orStokIt6q1Y0j4u/ArKoVzTZA7paxWns4/Rwu6UVJl0n6tqT5wOsAkvpIOitdbOTvkp6WNK70Ikqcny5AsVLS9cDAsjoVu2UkfUHSnyX9TdISSbdI2kLSZOAY4J9LupLOLzlvtKQ56XmLJX1PUv+yax+TxvuWpJnA7rX532ZWW265W60NTz8Xp5+fBeYBX+Kdf2//A4wDLgDmAp8EJkl6NSJ+ldb5CnAu8F2S3wQ+A3yv2s0lfSu97lXAmcCmwKeAzUi6jN4LbJnGA8mUyUgaA0wBrgHOBt4PXEzSAPqPtM4/ADcBtwGnA3sBN+f4f2JWfxHhzVuPNuB8YBlJ0u4HfAD4DUkLfTDwIkm/+MYl5+wCdALjyq51PTA7/d4XWAj8qKzONCCA4en+8HT/yHR/S2AVcHkXMd8C3F9WJuAl4Kdl5Z8H3gK2SfdvBh4nnbYjLTsnjeHERv99ePNWurlbxnprG2B1uj1F8lD1uIhYlB6fHhF/K6l/CElyv01SvzUbMB0YkS4jOIzkh8MdZfe6tUosBwCbAD/t5p/hAyQt+pvLYpoBbEzSQodkFaw7I6J0QqZqMZk1hLtlrLdWAJ8gab0uBhaWJb8lZfW3JWmZr8i43mBgh/T70rJj5fvltkk/F3VZa13bpp9TM46vmT9/hx7EZNYQTu7WW+0RMaeL4+XTji4H2oEDSVrw5Zbyzr/L7cuOle+XezX9HEzSXZTXmrVH24A/Vjj+Qvq5uAcxmTWEk7vV2wySlvsWETGtUgVJL5Mk0tHAPSWHPlPl2g+S9JGPI30IWsHbJF0tpZ4iWc1qeET8uIvrzwaOkvTNkt9OqsVk1hBO7lZXEfGUpKuBGyV9D5hDkmz3BD4QESdHREd67FJJy0hGyxwDfLDKtf8q6ULgO+kqVVOB95CMlvnPiFhA8sLTaElHk4yUWRgRCyV9DfiZpIHA3SQ/BHYGjgaOjYhVwH8BD5H0zV9L0hfvRTGsKfmBqjXCl0mGJZ5AkoAnkyTgmSV1vk8yDPJU4JckQxm/Xu3CEXEx8EWS5wB3kAxt3BJYmVa5CrgPmETSEm9Lz7uJ5DeFESQvX91KMlxyLkmiJ+1+GgvsA9xOkviP6+4f3qwevBKTmVkBueVuZlZATu5mZgXk5G5mVkBO7mZmBeTkbmZWQE7uZmYF5ORuZlZATu5mZgX0/wHmu/yUdpO2aAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = [[22,2],\n",
    "          [0,14]]\n",
    "\n",
    "sn.heatmap(heatmap, annot=True)\n",
    "\n",
    "\n",
    "plt.ylabel('Actual', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.xlabel('Predicted', fontsize = 15) # y-axis label with fontsize 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc91cb9d400>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "preds = model.predict(X_test,batch_size=10)\n",
    "confusion_matrix = pd.crosstab(y_test.argmax(axis=1),preds.argmax(axis=1), rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(heatmap, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix = confusion_matrix(y_test.argmax(axis=1),preds.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dataDirectory = r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/2/nisanpat005/\"\n",
    "lungPatients = os.listdir(dataDirectory)\n",
    "lungPatients[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predzz=[]\n",
    "ct1t = ct2.reshape(ct2.shape[0],40,144,144,1)\n",
    "for i in ct1t:\n",
    "    predzz.append(model.predict(np.expand_dims(i, axis=0)).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i, x in enumerate(predzz) if x == [[0]]]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[84][20],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[84][20],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for i in range(21):\n",
    "    test1 =np.expand_dims(testData[i], axis=0)\n",
    "    pred = model.predict(test1)\n",
    "    indices = np.where(pred[0] == pred[0].max())\n",
    "    if indices[0][0]==0:\n",
    "        b.append(0)\n",
    "    if indices[0][0]==1:\n",
    "        b.append(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test1)\n",
    "indices = np.where(pred[0] == pred[0].max())\n",
    "if indices[0][0]==0:\n",
    "    print(\"Negative\")\n",
    "if indices[0][0]==1:\n",
    "    print(\"Positive\")\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scan(path):\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices\n",
    "\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 0\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):\n",
    "        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_patient = load_scan(r\"/mnt/tempvol/home/ubuntu/Desktop/Ctdata/2/nisanpat013/stu01/ser01/\")\n",
    "first_patient_pixels = get_pixels_hu(first_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_resampled= resample(first_patient_pixels, first_patient, [1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_resampled = np.array(pix_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('covidctML55_model.h5',include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_resampled[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, BatchNormalization, Dense,Conv3D,Flatten,add\n",
    "from keras.layers import AvgPool2D,AvgPool3D,GlobalAveragePooling2D,GlobalAveragePooling3D, MaxPool2D,MaxPool3D\n",
    "from keras.models import Model\n",
    "from keras.layers import ReLU, concatenate\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(25,180,180,1))\n",
    "x = Conv3D(64, kernel_size=(5,7,7))(visible)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "\n",
    "#first resblock\n",
    "shortcut = x\n",
    "shortcut = Conv3D(64, kernel_size=(1,3,3), strides=(1,1,1), padding='same')(shortcut)\n",
    "shortcut = BatchNormalization()(shortcut)\n",
    "shortcut = ReLU()(shortcut)\n",
    "x = add([shortcut, x])\n",
    "\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "\n",
    "#second resblock\n",
    "shortcut = x\n",
    "shortcut = Conv3D(64, kernel_size=(1,3,3), strides=(1,1,1), padding='same')(shortcut)\n",
    "shortcut = BatchNormalization()(shortcut)\n",
    "shortcut = ReLU()(shortcut)\n",
    "x = add([shortcut, x])\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv3D(32, kernel_size=(3,3,3),padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "output = Dense(2, activation='sigmoid')(x)\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet(input_shape, n_classes, filters = 32):\n",
    "    \n",
    "    #batch norm + relu + conv\n",
    "    def bn_rl_conv(x,filters,kernel=1,strides=1):\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(filters, kernel, strides=strides,padding = 'same')(x)\n",
    "        return x\n",
    "    \n",
    "    def dense_block(x, repetition):\n",
    "        \n",
    "        for _ in range(repetition):\n",
    "            y = bn_rl_conv(x, 4*filters)\n",
    "            y = bn_rl_conv(y, filters, 3)\n",
    "            x = concatenate([y,x])\n",
    "        return x\n",
    "        \n",
    "    def transition_layer(x):\n",
    "        \n",
    "        x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )\n",
    "        x = AvgPool2D(2, strides = 2, padding = 'same')(x)\n",
    "        return x\n",
    "    \n",
    "    input = Input (input_shape)\n",
    "    x = Conv2D(64, 7, strides = 2, padding = 'same')(input)\n",
    "    x = MaxPool2D(3, strides = 2, padding = 'same')(x)\n",
    "    \n",
    "    for repetition in [6,12,16]:\n",
    "        \n",
    "        d = dense_block(x, repetition)\n",
    "        x = transition_layer(d)\n",
    "    x = GlobalAveragePooling2D()(d)\n",
    "    output = Dense(n_classes, activation = 'softmax')(x)\n",
    "    \n",
    "    model = Model(input, output)\n",
    "    return model\n",
    "input_shape = 224, 224, 3\n",
    "n_classes = 3\n",
    "model = densenet(input_shape,n_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
